% falar de implementações, unicode

O presente trabalho visa aplicar técnicas de redes convolucionais na classificação de sentimento de \textit{tweets}.
Este processo será dividido em duas etapas.
A primeira se constitui em criar uma base de dados de treinamento como descrito por Go \textit{et at.}~\cite{go09} e
replicar os resultados obtidos com técnicas tradicionais de aprendizado de máquina aplicados a texto.
Em seguida reproduzir a aplicação de redes convolucionais como descrito por Kim~\cite{kim14}.

O trabalho de Go \textit{et at.}~\cite{go09} visa definir um sistema de classificação de sentimento sem a necessidade de
anotação manual dos dados para treinamento, utilizando a técnica de supervisão distante.
Apesar do termo \textit{análise de sentimento} ter definição ambígua na literatura, nesse contexto estaremos tratando da
extração de polaridade, negativa ou positiva, de uma mensagem.
Em especial, as mensagens tratadas nesse trabalho são originárias do Twitter, serviço de microblogs.

Embora já existisse uma ampla gama de estudos em análise se sentimento, Go \textit{et at.} apresentaram o primeiro
trabalho referente a \textit{tweets}.
A principal característica das mensagens de microblogs são seu tamanho reduzido, no caso do Twitter limitadas a
140 caracteres.
Devido a esse fato e ao meio no qual as mensagens estão inseridas, é observáveis variações idiomáticas especificas deste
contexto.
Outro traço notável é que por ser uma plataforma aberta, o Twitter é composto de mensagens dos mais diversos domínios.
Esse fator dificulta a tarefa a ser executada quando comparado com trabalhos de um domínio específico, como por exemplo
a análise de sentimento para avaliação de filmes a partir de resenhas; ou na predição de flutuações do mercado financeiro
considerando artigos jornalísticos.
Além das características textuais, os \textit{tweets} também são compostos de atributos como: republicação ou citação de
mensagens, a presença de fotos e video, as conexões entre os usuários, local de envio, horário, número de curtidas etc.
Tais variáveis podem colaborar na realização de tarefas como a análise de sentimento, porém, este trabalho aborda apenas
as características textuais.

A não dependência de anotação dos dados e a facilidade de coleta dos \textit{tweets}, por meio de interface programável,
viabilizam a formação de uma grande base de treinamento.
Para a realização deste trabalho foram coletados cerca de 50 milhões de mensagens filtradas apenas pelo idiomas inglês,
estes \textit{tweets} compõe a base de treinamento.
Posteriormente, se aplica o método de classificação ruidosa de sentimento desenvolvido por Read~\cite{read05} como
especificado na seção~\ref{distant_supervision}.

A base de teste por sua vez é composta de \textit{tweets} anotados manualmente.
Essa base é composta da coletânea de dados disponibilizados pela conferencia anual \textit{Semantic Evaluation}
(SemEval)~\cite{semeval17} entre os anos de 2013 a 2017.
Esta base é composta de cerca de 70 mil \textit{tweets} e processo de anotação destes dados foi feito manualmente através
da plataforma CrowdFlower, mais detalhes sobre a formação da base de dados são apresentados por Rosenthal
\textit{et al.}~\cite{rosenthal17}, organizadores do evento.

Neste projeto foram utilizadas a biblioteca NLTK~\cite{nltk}, desenvolvida em \textit{Python} para remoção de stopwords
e tokenização das mensagens de ambas as bases.
SpaCy~\cite{spacy} é outra biblioteca relevante no tratamento de linguagem natural, também escrita em \textit{Python}.

Foram replicadas as técnicas abordadas por Go \textit{et al.}, \textit{Support Vector Machine} (SVM) e
\textit{Naïve Bayes} (NB), validando os resultados obtidos com o conjunto de dados coletados.
Em razão da pequena variação nos resultados obtidos por Go, foram replicados apenas as representações por unigrama.
Dada a grande quantidade de dados e as limitações computacionais, o modelo SVM utilizado foi treinado a partir do método
do gradiente como descrito por Suykens e Vandewalle~\cite{suykens99}.
Foi utilizada as implementações de NB e SVM disponibilizadas pela biblioteca Scikit-Learn~\cite{sklearn}.

Em seguida, foi gerado um \textit{embedding}, pelo algoritmo Word2Vec, a partir da base de treinamento.
O desenvolvimento de um \textit{embedding} treinado a partir de dados da mesma fonte a ser classificada permite sua
melhor acurácia, visto que as mensagens tem variações de linguagens próprias do meio.
Este treinamento foi feito utilizando a biblioteca Gensim~\cite{gensim}.

Por fim, gerou-se um modelo de redes convolucionais aplicando como entrada a representação obtida pelo Word2Vec, como
descrito por Kim~\cite{kim14}.
A implementação da rede convolucional foi feita utilizando a biblioteca Keras~\cite{keras}.
A escolha dos hiper-parâmetros a serem testados foi baseada na submissão ao SemEval de Derius
\textit{et al.}~\cite{deriu16}, a qual obteve melhor resultado na edição de 2016.
Apesar de Kim~\cite{kim14} ter obtido melhores resultados utilizando \textit{fine-tuning} do \textit{embedding}, a
tentativa de utilização do mesmo resultou em grande aumento do \textit{overfit}.
Kim, entretanto, já ressaltava a dificuldade de generalização dos modelos treinados com \textit{fine-tuning}.
A seleção dos hiper-parâmetros foi determinada de maneira a maximizar a área sobre a curva de operação do receptor (ROC).
