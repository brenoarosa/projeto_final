Este capítulo tem como objetivo descrever a elaboração de modelos de aprendizado de máquina capazes de classificar
sentimento, positivo ou negativo, de \textit{tweets}.
A produção desse modelo será feita a partir de base de dados anotada de maneira automatizada, permitindo a sua
fácil replicação.

\section{Bases de Dados} \label{sec:data}

O trabalho Sentiment140, desenvolvido por Go \textit{et al.}~\cite{go09} visa a definir um sistema de classificação de
sentimento sem a necessidade de anotação manual dos dados para treinamento, utilizando a técnica de supervisão distante.
Conjuntamente com o artigo, Go \textit{et al.} disponibilizaram um base de dados formada por supervisão distante composta
de 800 mil \textit{tweets}, divididos igualmente entre as classes positivas e negativas, e uma pequena base de testes de
360 \textit{tweets} anotados manualmente, também divididos igualmente entre as classes.

A não dependência de anotação dos dados e a facilidade de coleta dos \textit{tweets}, por meio de interface programável,
viabilizam a formação de uma grande base de treinamento.
Para a realização deste trabalho foram coletados cerca de 40 milhões de mensagens amostradas do conjunto total de
\textit{tweets}, filtrando-as apenas pelo idioma inglês.
Essas mensagens foram coletadas entre os anos de 2015 e 2017 a partir de interface programável oferecida pelo Twitter.

Posteriormente, se aplicou o método de classificação ruidosa de sentimento desenvolvido por Read~\cite{read05} como
especificado na Seção~\ref{sec:distant_supervision} nos \textit{tweets} coletados.
Nesse método, são definidos grupos de \textit{emoticons} positivos e negativos.
Mensagens que possuíram \textit{emoticons} pertencentes a algum destes grupos foram anotadas com as respectivas classes.
Caso \textit{emoticons} de ambos os grupos estejam presentes em uma mesma mensagem esta será descartada.
Os \textit{emoticons} utilizados para anotação da base de dados foram removidos das mensagens para evitar introduzir
viés ao classificador.

A Tabela~\ref{tab:emoticons} mostra os \textit{emoticons} escolhidos para compor a anotação ruidosa.
Em adição aos \textit{emoticons} presentes no Sentiment140, foram classificados manualmente os emoticons com maior
número de aparições nas mensagens coletadas.
Estudos indicam que a escolha dos \textit{emoticons} pode definir quão ruidosa é a anotação automática.
Durante este processo, observou-se um grande desbalanceamento entre classes, na qual os \textit{tweets} positivos
compõem 80\% do volume total de anotações.

\begin{table}[h]
    \begin{center}
        \begin{tabular}{| c | c |}
        \hline
        \textbf{Negativos} & \textbf{Positivos} \\ \hline
        :( & :) \\ \hline
        =( & =) \\ \hline
        :-( & :-) \\ \hline
        :'( & :D \\ \hline
        \includegraphics[height=1em]{emojis/1F62D.pdf} & \includegraphics[height=1em]{emojis/1F60D.pdf} \\ \hline
        \includegraphics[height=1em]{emojis/1F612.pdf} & \includegraphics[height=1em]{emojis/1F602.pdf} \\ \hline
        \includegraphics[height=1em]{emojis/1F622.pdf} & \includegraphics[height=1em]{emojis/1F60D.pdf} \\ \hline
        \includegraphics[height=1em]{emojis/1F614.pdf} & \includegraphics[height=1em]{emojis/1F60A.pdf} \\ \hline
        \includegraphics[height=1em]{emojis/1F62A.pdf} & \includegraphics[height=1em]{emojis/1F618.pdf} \\ \hline
                                                       & \includegraphics[height=1em]{emojis/1F495.pdf} \\ \cline{2-2}
                                                       & \includegraphics[height=1em]{emojis/2665.pdf} \\ \cline{2-2}
                                                       & \includegraphics[height=1em]{emojis/2764.pdf} \\ \cline{2-2}
                                                       & \includegraphics[height=1em]{emojis/1F49B.pdf} \\ \cline{2-2}
                                                       & \includegraphics[height=1em]{emojis/1F499.pdf} \\ \cline{2-2}
                                                       & \includegraphics[height=1em]{emojis/1F49A.pdf} \\ \hline


        \end{tabular}
        \caption{Emoticons selecionados para aplicação de supervisão distante.}
        \label{tab:emoticons}
    \end{center}
\end{table}

A base de teste, por sua vez, é composta de \textit{tweets} anotados manualmente.
Essa base é formada pela coletânea de dados disponibilizados pela conferencia anual \textit{Semantic Evaluation}
(SemEval)~\cite{semeval17} entre os anos 2013 e 2017.
Esta base é composta de cerca de 70 mil \textit{tweets} e classificados entre positivos, neutros ou negativos.
Como este trabalho considera apenas as classes positivas e negativas, foram descartados as mensagens neutras.
O processo de anotação destes dados foi feito manualmente através da plataforma CrowdFlower, na qual cada mensagem
foi avaliado por pelo menos 5 pessoas e a anotação foi considerada válida se 3 ou mais participantes apresentaram a
mesma avaliação, como descrito por Rosenthal \textit{et al.}~\cite{rosenthal17}, organizadores do evento.
Novamente foram removidos os \textit{emoticons} presentes na anotação ruidosa para evitar introdução de tendência.

\section{Figuras de Mérito} \label{sec:metrics}

Uma vez definidos os dados, se faz necessário definir como será avaliada a performance dos modelos a serem treinados.
Esta seção apresentará as figuras de mérito utilizadas para seleção de parâmetros e avaliação dos algoritmos.

A forma mais direta de se medir a performance de um modelo é considerar a sua acurácia, que é a média aritmética das
eficiências de cada uma das classes.
Todavia, a presença de desbalanceamento de classes nos dados pode favorecer a acertividade da classe mais presente
enquanto perde eficiência na classificação da classe com menos exemplos.

% ROC - dissertacao fernando
A curva ROC (\textit{receiver operating characteristic})~\cite{bradley97} é uma forma de visualizar a performance de um
classificador binário para seleção de um ponto de operação.
Nela, a probabilidade de detecção e falso alarme variam com a escolha do patamar de decisão.
Um classificador ideal, que atinge 100\% de probabilidade de detecção sem nenhum caso de falso alarme, é representado na
curva ROC como um degrau.
Desta forma, a área sob a curva (AUC) pode ser utilizada como métrica de eficiência para um classificador.

% SP - dissertacao fernando
O índice SP~\cite{ciodaro12} é outro método de avaliação de classificadores binários.
A Equação~\ref{eq:sp} descreve a formação desse índice na qual $P_c$ representa a probabilidade de detecção da classe
positiva enquanto $P_{nc}$ caracteriza a probabilidade de não obtenção de falso alarme.

\begin{equation} \label{eq:sp}
    SP = \sqrt{\sqrt{P_c P_{nc}} \left(\frac{P_c + P_{nc}}{2}\right)}
\end{equation}

O patamar de decisão do classificador será escolhido de maneira a maximizar o índice SP.
Pois este será um ponto de operação que apresenta um compromisso entre a eficiência de ambas as classes.

% validaçao cruzada, ver dissertação do junior
Uma maneira de garantir que os resultados obtidos pelas figuras de mérito apresentadas sejam consistentes independente do
conjunto de dados na qual será aplicado é utilizar a validação cruzada.
Neste trabalho será utilizado o método de validação cruzada de K-partições~\cite{kohavi95}.
Este processo consiste na separação aleatória da base de dados em $k$ conjuntos mutualmente exclusivos de tamanhos
similares.
Posteriormente são executadas $k$ rodadas, na qual o conjunto correspondente a cada rodada será utilizado para validação
do modelo enquanto os outros $k-1$ conjuntos servirão para seu treinamento.

\section{Desenvolvimento} \label{sec:desenvolvimento}

% Etapa 1
O presente trabalho será dividido em três etapas.
Na primeira fase se utilizará a base de dados provida por Go \textit{et al.}~\cite{go09} replicando as técnicas
abordadas em seu artigo com objetivo de validar os pré-processamentos e algoritmos aplicados.
Para tal, serão utilizadas as bases de dados tanto de treinamento como de testes disponibilizadas no
Sentiment140~\cite{go09}.

Se começará pela tokenização dos \textit{tweets}, durante esse processo serão removidos \textit{stopwords}; links;
referências a usuários; e cada token será transformado para forma minuscula.
Será replicado como entrada do algoritmo de aprendizado apenas a representação dos tokens por unigrama, essa escolha foi
feita por ser a representação mais simples e por Go \textit{et at.}~\cite{go09} mostrar que há pouca variação de
resultado entre as diferentes representações.
A Tabela~\ref{tab:go} apresenta a acurácia dos classificados de Go \textit{et al}, nela são ressaltadas que a utilização
de representações mais complexas apesar de melhorar a acurácia quando combinada com alguns algoritmos como Naïve Bayes
também resulta em perda de eficiência em outros, por exemplo, SVM.
Considerando ainda o número reduzido de casos do banco de dados de teste, não foi considerada a diferença de performance
entre as diferentes formas de representação significantes o suficiente para justificar sua utilização.

\begin{table}[h]
    \begin{center}
        \begin{tabular}{| l | r | r | r |}
        \hline
        \textbf{Representação} & \textbf{Naïve Bayes} & \textbf{Máxima Entropia} & \textbf{SVM} \\ \hline
        Unigrama & 81,3\% & 80,5\% & 82,2\% \\ \hline
        Bigrama &  82,6\% & 79,1\% & 78,8\% \\ \hline
        Unigrama + Bigrama & 82,7\% & 83,0\% & 81,6\% \\ \hline
        Unigrama + \textit{Part of Speech} & 82,7\% & 83,0\% & 81,6\% \\ \hline
        \end{tabular}
        \caption{Acurácia obtida pelos classificadores do Sentiment140~\cite{go09}.}
        \label{tab:go}
    \end{center}
\end{table}

Dos classificadores apresentados por Go \textit{et al.} foram selecionados os algoritmos de Naïve Bayes e
\textit{Support Vector Machine} para validar as etapas de pré-processamento e as implementações dos algoritmos
a serem utilizadas.

Serão utilizados Naïve Bayes com distribuição multinomial, por se adequar ao pré-processamento utilizado.
Será variado o parâmetro de suavização de distribuição de Laplace, de maneira a otimizar a acurácia.
Neste caso, a acurácia será otimizada dado que os dados de treinamento são balanceados

Para treinamento do modelo por \textit{Support Vector Machines}, dada a grande quantidade de dados e as limitações
computacionais, será empregado o treinamento a partir do método do gradiente como descrito por Suykens e
Vandewalle~\cite{suykens99}.
A função \textit{kernel} utilizada será linear, assim como feito por Go \textit{et al.}
Neste caso, será variado o parâmetro de regularização $L_{2}$ também objetivando maximizar a acurácia.

Será empregada a validação cruzada por K-partições, com 10 partições, no treinamento dos dois algoritmos.
Findada a seleção dos parâmetros de regularização, será avaliado o desempenho dos classificadores comparados aos resultados
apresentados por Go \textit{et al.}

% Etapa 2
A segunda etapa consiste em treinar os mesmos algoritmos de Naïve Bayes e SVM utilizados anteriormente porém utilizando
a base de dados anotada desenvolvida com supervisão distante.
Os resultados obtidos nesta fase servirão como base de comparação entre os modelos lineares e modelos formados técnicas
de \textit{Deep Learning}.
Adicionalmente, será validado o processo de captação de dados e anotação por supervisão distante.
Nesta fase serão replicados os mesmos procedimentos práticos da etapa anterior.

Entretanto, devido a base de dados coletada ser desbalanceada, durante o treinamento do modelo por
\textit{Support Vector Machines} é necessário dar pesos diferentes a cada exemplo de maneira que cada classe pese
igualmente durante o treinamento.
Tal correção não se faz necessária no modelo por Naïve Bayes pois este considera a probabilidade de presença das classes.
Por sua vez, a métrica utilizada para seleção dos parâmetros neste caso será a área sob a curva ROC visto que a seleção por
acurácia favorece modelos enviesados a classe mais presente nos dados.
Uma vez selecionados, os parâmetros serão analisados com base em sua performance na classificação das bases de testes tanto
do Sentiment140 quanto do SemEval.

% Etapa 3
Por fim, a terceira e última etapa é formada pela aplicação de redes convolucionais em textos como descrito por
Kim~\cite{kim14}.
Nesta fase será medido o impacto da utilização desta técnica na classificação de mensagens.
Serão variados diferentes pré-processamentos e parâmetros das redes para analisar sua influência na eficiência do
modelo.

Para utilização de modelos de redes convolucionais, precisa-se primeiro representar os dados por um \textit{embedding}.
Neste sentido, será utilizado o \textit{embedding} Word2Vec pré-treinado a partir de notícias em inglês, disponibilizado
pelo Google.
Este Word2Vec é treinado de maneira a representar cada token como um vetor de 300 dimensões.

Posteriormente, serão gerados modelos de redes convolucionais nos quais a representação obtida pelo Word2Vec será utilizada
como entrada da rede.
A escolha dos hiperparâmetros a serem testados foi baseada na submissão ao SemEval de Derius
\textit{et al.}~\cite{deriu16}, a qual obteve o melhor resultado na SemEval 2016.
Compõem os hiperparâmetros a serem variados: número de camadas, número de filtros convolucionais por camada, tamanho dos filtros
convolucionais, tamanho do filtro de \textit{pooling}.
Os parâmetros de regularização $L_{2}$ e probabilidade de Dropout se manterão fixos, sendo seus valores também iguais aos
propostos por Derius \textit{et al.}

Para o treinamento das redes convolucionais serão sorteados os dados anotados de maneira ruidosa em dois grupos:
treinamento, contendo 80\% do volume total, e validação com os 20\% restante.
Não será aplicada a validação cruzada, como nas etapas anteriores, visto o alto custo computacional de treinamento de cada
rede.
O treinamento se dará até que o valor da função custo sob os dados de treinamento se estabilize em um valor
arbitrariamente pequeno, $\epsilon$.
Entretanto, para reduzir o efeito do \textit{overfitting}, será aplicado \textit{early stopping}~\cite{caruana01},
técnica que consiste em utilizar os pesos obtidos na época de treinamento que corresponde ao menor valor de função custo
aplicada ao conjunto de validação.
A função custo a ser aplicada será a entropia cruzada e será utilizado o otimizador por método do gradiente \textit{Adam}.

Assim como aplicado na modelagem por SVM na segunda etapa, será necessário compensar o desbalanceamento das classes
através de pesos diferentes para cada classe.
A seleção dos hiperparâmetros de melhor performance será feita a partir daquele que obtiver maior valor de área sob a curva
ROC.
