Este capítulo visa descrever a elaboração de um modelo de \textit{deep learning} capaz de classificar sentimento,
positivo ou negativo, de \textit{tweets}.
A produção desse modelo será feita a partir de base de dados anotada de maneira automatizada, permitindo a sua
fácil replicação.

\section{Bases de Dados} \label{sec:data}

O trabalho Sentiment140, desenvolvido por Go \textit{et al.}~\cite{go09} visa definir um sistema de classificação de
sentimento sem a necessidade de anotação manual dos dados para treinamento, utilizando a técnica de supervisão distante.
Conjuntamente com o artigo, Go \textit{et al.} disponibilizaram um base de dados formada por anotação ruidosa composta
de 800 mil \textit{tweets}, divididos igualmente entre as classes positivas e negativas, e uma pequena base de testes de
360 \textit{tweets} anotados manualmente, também divididos igualmente entre as classes.

A não dependência de anotação dos dados e a facilidade de coleta dos \textit{tweets}, por meio de interface programável,
viabilizam a formação de uma grande base de treinamento.
Para a realização deste trabalho foram coletados cerca de 40 milhões de mensagens do Twitter filtrando-as apenas pelo
idioma inglês.
Posteriormente, se aplica o método de classificação ruidosa de sentimento desenvolvido por Read~\cite{read05} como
especificado na Seção~\ref{sec:distant_supervision} nos \textit{tweets} coletados.
Nesse método, são definidos grupos de \textit{emoticons} positivos e negativos.
Mensagens que possuírem \textit{emoticons} pertencentes a algum destes grupos serão anotadas com as respectivas classes,
caso \textit{emoticons} de ambos os grupos estejam presentes em uma mesma mensagem esta será descartada.
Os \textit{emoticons} utilizados para anotação da base de dados foram removidos das mensagens para evitar introduzir
viés ao classificador.

A tabela~\ref{tab:emoticons} mostra os \textit{emoticons} escolhidos para compor a anotação ruidosa.
Em adição aos \textit{emoticons} presentes no Sentment140, foram classificados manualmente os emoticons mais presentes
na base de dados.
A escolha dos \textit{emoticons} definirá quão ruidosa será a anotação automática.
Durante este processo, observou-se um grande desbalanceamento nas classes, na qual os \textit{tweets} positivos
compões 80\% do volume total de anotações.

% completar com todos
\begin{table}[h]
    \begin{center}
        \begin{tabular}{| c | c |}
        \hline
        \textbf{Negativos} & \textbf{Positivos} \\ \hline
        :( & :) \\ \hline
        =( & =) \\ \hline
        :-( & :-) \\ \hline
        :'( & :D \\ \hline
        \includegraphics[height=1em]{emojis/1F62D.pdf} & \includegraphics[height=1em]{emojis/1F60D.pdf} \\ \hline
        \includegraphics[height=1em]{emojis/1F612.pdf} & \includegraphics[height=1em]{emojis/1F602.pdf} \\ \hline
        \includegraphics[height=1em]{emojis/1F622.pdf} & \includegraphics[height=1em]{emojis/1F60D.pdf} \\ \hline
        \includegraphics[height=1em]{emojis/1F614.pdf} & \includegraphics[height=1em]{emojis/1F60A.pdf} \\ \hline
        \includegraphics[height=1em]{emojis/1F62A.pdf} & \includegraphics[height=1em]{emojis/1F618.pdf} \\ \hline
                                                       & \includegraphics[height=1em]{emojis/1F495.pdf} \\ \cline{2-2}
                                                       & \includegraphics[height=1em]{emojis/2665.pdf} \\ \cline{2-2}
                                                       & \includegraphics[height=1em]{emojis/2764.pdf} \\ \cline{2-2}
                                                       & \includegraphics[height=1em]{emojis/1F49B.pdf} \\ \cline{2-2}
                                                       & \includegraphics[height=1em]{emojis/1F499.pdf} \\ \cline{2-2}
                                                       & \includegraphics[height=1em]{emojis/1F49A.pdf} \\ \hline


        \end{tabular}
        \caption{Emoticons selecionados para aplicação de supervisão distante.}
        \label{tab:emoticons}
    \end{center}
\end{table}

A base de teste por sua vez é composta de \textit{tweets} anotados manualmente.
Essa base é formada pela coletânea de dados disponibilizados pela conferencia anual \textit{Semantic Evaluation}
(SemEval)~\cite{semeval17} entre os anos de 2013 a 2017.
Esta base é composta de cerca de 70 mil \textit{tweets} e processo de anotação destes dados foi feito manualmente
através da plataforma CrowdFlower, mais detalhes sobre a formação da base de dados são apresentados por Rosenthal
\textit{et al.}~\cite{rosenthal17}, organizadores do evento.
Novamente foram removidos os \textit{emoticons} presentes na anotação ruidosa.

\section{Métricas} \label{sec:metrics}

Uma vez definidos os dados e as técnicas de classificação, se faz necessário medir a qualidade dos modelos obtidos.
Esta seção apresentará as métricas utilizadas para seleção de parâmetros e avaliação dos algoritmos.

A forma mais direta de se medir a performance de um modelo é considerar a sua acurácia.
Todavia, a presença de desbalanceamento de classes nos dados pode favorecer a acertividade da classe mais presente
enquanto perde eficiência na classificação da classe com menos exemplos.

% ROC - dissertacao fernando
A curva ROC (\textit{receiver operating characteristic})~\cite{bradley97} é uma forma de visualizar a performance de um
classificador binário para seleção de um ponto de operação.
Nela se apresenta a variação da probabilidade de detecção e de falso alarme variam com a escolha do patamar de decisão.
A área sob a curva (AUC) pode ser utilizada como métrica de eficiência para um classificador.

% SP - dissertacao fernando
O índice SP é outro método de avaliação de classificadores binários.
A equação~\ref{eq:sp} descreve a formação desse índice na qual $P_c$ representa a probabilidade de detecção da classe
positiva enquanto $P_{nc}$ caracteriza a probabilidade de não obtenção de falso alarme~\cite{ciodaro12}.

\begin{equation} \label{eq:sp}
    SP = \sqrt{\sqrt{P_c P_{nc}}(\frac{P_c + P_{nc}}{2})}
\end{equation}

O patamar de decisão do classificador será escolhido de maneira a maximizar o índice SP.

% validaçao cruzada, ver dissertação do junior
Uma maneira de garantir que os resultados obtidos pelas métricas apresentadas sejam consistentes independente do
conjunto de dados na qual será aplicado é utilizar a validação cruzada.
Neste trabalho será utilizado o método de validação cruzada de K-partições.
Este processo~\cite{kohavi95} consiste na separação aleatória da base de dados em $k$ conjuntos mutualmente exclusivos
de tamanhos similares.
Posteriormente são executadas $k$ rodadas, na qual o conjunto correspondente a cada rodada será utilizado para validação
do modelo enquanto os outros $k-1$ conjuntos servirão para seu treinamento.
O treinamento pode ser considerado consistente se obtiver pouca variação nos resultados das $k$ rodadas.

\section{Desenvolvimento} \label{sec:desenvolvimento}

% Etapa 1
O presente trabalho será dividido em três etapas.
Na primeira fase utilizou-se a base de dados provida por Go \textit{et al.}~\cite{go09} replicando as técnicas
abordadas em seu artigo visando validar os pré-processamentos e algoritmos aplicados.
Para tal, serão utilizadas as bases de dados tanto de treinamento como de testes disponibilizadas no
Sentiment140~\cite{go09}.

Começou-se tokenizando os \textit{tweets}, durante esse processo removeram-se \textit{stopwords}; links; referências a
usuários; e cada token foi transformado para forma minuscula.
Replicou-se como entrada do algoritmo de aprendizado apenas a representação dos tokens por unigrama, essa escolha foi
feita por ser a representação mais simples e por Go \textit{et at.}~\cite{go09} mostrar que há pouca variação de
resultado entre as diferentes representações como apresentado na Tabela~\ref{tab:go}.

\begin{table}[h]
    \begin{center}
        \begin{tabular}{| l | r | r | r |}
        \hline
        \textbf{Representação} & \textbf{Naïve Bayes} & \textbf{Máxima Entropia} & \textbf{SVM} \\ \hline
        Unigrama & 81,3\% & 80,5\% & 82,2\% \\ \hline
        Bigrama &  82,6\% & 79,1\% & 78,8\% \\ \hline
        Unigrama + Bigrama & 82,7\% & 83,0\% & 81,6\% \\ \hline
        Unigrama + \textit{Part of Speech} & 82,7\% & 83,0\% & 81,6\% \\ \hline
        \end{tabular}
        \caption{Acurácia obtida pelos classificadores do Sentiment140.}
        \label{tab:go}
    \end{center}
\end{table}

Em seguida, foram treinados os algoritmos de Naïve Bayes e SVM, estes foram escolhidos por existirem implementações de
código aberto disponíveis e de fácil acesso.
Utilizou-se Naïve Bayes com distribuição multinomial, por se adequar ao pré processamento utilizado.
Variou-se o parâmetro de suavização de distribuição de laplace, de maneira a otimizar a acurácia.
Para treinamento do modelo por \textit{support vector machines}, dada a grande quantidade de dados e as limitações
computacionais, foi empregado o treinamento a partir do método do gradiente como descrito por Suykens e
Vandewalle~\cite{suykens99}.
A função \textit{kernel} utilizada foi linear.
Neste caso, variou-se parâmetro de regularização L2 também visando maximizar a acurácia.
Empregou-se validação cruzada por K-partições, com 10 partições, no treinamento dos dois algoritmos.
Findada a seleção dos modelos, se avaliou o desempenho dos classificadores comparados aos resultados apresentados por Go
\textit{et al.}

% Etapa 2
A segunda etapa consiste em treinar os mesmos algoritmos de Naïve Bayes e SVM utilizados anteriormente porém utilizando
a base de dados anotada desenvolvida com supervisão distante, como elucidado na Seção~\ref{sec:data}.
Os resultados obtidos nesta fase servirão como base de comparação entre os modelos lineares e modelos formados técnicas
de \textit{deep learning}.
Adicionalmente, será validado o processo de captação de dados e anotação por supervisão distante.
Nesta fase replicou-se os mesmos procedimentos práticos da etapa anterior.

Entretanto, devido a base de dados coletada ser desbalanceada, durante o treinamento do modelo por
\textit{support vector machines} foi necessário dar pesos diferentes a cada exemplo de maneira que cada classe pesasse
igualmente durante o treinamento.
Tal correção não se faz necessária no modelo por Naïve Bayes pois este considera a probabilidade de presença das classes,
como descrito na Seção~\ref{sec:bayes}.
Por sua vez, a métrica utilizada para seleção do modelo neste caso será a área sob a curva ROC visto que a seleção por
acurácia favorece modelos enviesados a classe mais presente nos dados.
Uma vez selecionados, os modelos foram analisados com base em sua performance na classificação das bases de testes tanto
do Sentiment140 quanto do SemEval.

% Etapa 3
Por fim, a terceira e última etapa é formada pela aplicação de redes convolucionais em textos como descrito por
Kim~\cite{kim14}.
Nesta fase será medido o impacto da utilização desta técnica na classificação de mensagens.
Serão variados diferentes pré-processamentos e parâmetros das redes para analisar sua influência na eficiência do
modelo.

Para utilização de modelos de redes convolucionais, precisa-se primeiro representar os dados por um \textit{embedding}.
Neste sentido, utilizou-se o \textit{embedding} Word2Vec pré-treinado a partir de notícias em inglês, disponibilizado
pelo Google.
Este Word2Vec é treinado de maneira a representar cada token como um vetor de 300 dimensões.

Posteriormente, geraram-se modelos de redes convolucionais nos quais a representação obtida pelo Word2Vec foi utilizada
como entrada da rede.
A escolha dos hiperparâmetros a serem testados foi baseada na submissão ao SemEval de Derius
\textit{et al.}~\cite{deriu16}, a qual obteve o melhor resultado da SemEval 2016.
Compõem os hiperparâmetros variados: número de camadas, número de filtros convolucionais por camada, tamanho dos filtros
convolucionais, tamanho do filtro de \textit{pooling}.
Os parâmetros de regularização L2 e probabilidade de Dropout se mantiveram fixos, sendo seus valores também iguais aos
propostos por Derius \textit{et al.}

Para o treinamento das redes convolucionais sortearam-se os dados anotados de maneira ruidosa em dois grupos:
treinamento, contendo 80\% do volume total, e validação com os 20\% restante.
Não se aplicou a validação cruzada, como nas etapas anteriores, visto o alto custo computacional de treinamento de cada
rede.
O treinamento se deu até que o valor da função custo sob os dados de treinamento se estabiliza-se em um valor
arbitrariamente pequeno, $\epsilon$.
Entretanto, para reduzir o efeito do \textit{overfitting}, foi aplicado \textit{early stopping}~\cite{caruana01},
técnica que consiste em utilizar os pesos obtidos na época de treinamento que corresponde ao menor valor de função custo
aplicada ao conjunto de validação.
A função custo aplicada foi a entropia cruzada e utilizou-se o otimizador por método do gradiente \textit{Adam}.

Assim como aplicado na modelagem por SVM na segunda etapa, foi necessário compensar o desbalanceamento das classes
através de pesos diferentes para cada classe.
A seleção do classificador de melhor performance foi feita a partir daquele que obteve maior valor de área sob a curva
ROC.
Por fim, se verificou se a utilização de redes convolucionais se desempenhou como o esperado na análise de sentimento
de \textit{tweets}.
